{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 - Catch-up from week 5 and filtering\n",
    "\n",
    "Filtering of sinusoidals is fairly straightforward. It is defined a the **convolution** of a filter (Usually denoted $h(n)$) and a time signal $x(n)$.\n",
    "\n",
    "**\"But wait, we already know about convolution using images and kernels?\"**\n",
    "\n",
    "Right you are! There is next to no difference from the convolution of images vs the convolution of signals. Where in convolution of images (usually called 2d convolution), you 'slide' a **kernel** across the image and calculate values like so. In signal convolution (usually called 1d convolution), you 'slide' a **filter** across the signal and calculate values. For a continuous signal, this looks like so (Notice the filter has been flipped as to perform convolution and not cross-correlation):\n",
    "\n",
    "<img src=\"images/Convolution.gif\" \n",
    "        style=\"display: block; margin: 0 auto\" />\n",
    "\n",
    "<img src=\"images/Discrete_convolution_1.gif\" \n",
    "        style=\"display: block; margin: 0 auto\" />\n",
    "\n",
    "In both cases, the filter that is plotted is usually called the **impulse response**. Explanations of this usually involve fancy maths about delta functions and whatever, but basically it is the output you get if you pass the filter over a function that consists of a single value (called a delta, or Dirac delta function):\n",
    "\n",
    "<img src=\"images/delta_function.png\"\n",
    "        alt='The Mighty Delta Function'\n",
    "        width = 800\n",
    "        height = 600\n",
    "        style=\"display: block; margin: 0 auto\" />\n",
    "\n",
    "You can think the **impulse response** as the \"shape\" of the filter, in the sense that you see how each new value is calculated.\n",
    "\n",
    "As for the actual formula for convolution of signal, it is defined both for discrete and continuous signals (we will only use the discrete case in this course):\n",
    " \n",
    "$$y(k) = x(n) * h(n) = \\sum^{\\infty}_{n=-\\infty} x(n) h(k - n)$$\n",
    "\n",
    "$$y(t) =  x(t) * h(t) = \\int^\\infty{-\\infty} x(t) h(t - \\tau) d\\tau$$\n",
    "\n",
    "## Filtering in the frequency domain\n",
    "\n",
    "First of, we can mention that you can take the fourier transform of a filter, just as you would a time signal. Next, probably mentioned before, but one nice property of the fourier transform, is that convolutions in the time domain become multiplications in the frequency domain.\n",
    "\n",
    "And that's pretty much all there is to it... This is really cool since convolution is a rather slow operation, and fourier transforms are not (thanks to the FFT). That means, it is sometimes faster to take the FFT of a signal, multiply it with a filter, and take the inverse FFT, than it is to simply convolve the time domain version of the singal with the time domain filter.\n",
    "\n",
    "**Another useful feature:** is that if you plot a filter in the frequency domain, it's impulse response will just show directly which frequencies will be attenuated or amplified, almost as a regular fourier transform plot would."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Fourier transform again (revised exercises from last time)\n",
    "\n",
    "**I may have screwed up a few places last time in regards to answers and formulas (sorry). If anything seems out of place compared to last week, the ground truth is here:**\n",
    "\n",
    "$$f_s : \\text{Sampling rate } \\frac{1}{T_s} \\text{ where $T_s$ is the distance between samples}$$\n",
    "\n",
    "$$N: \\text{Number of samples in total,sometimes calculated as} f_s \\cdot \\text{Duration (in seconds)}$$\n",
    "\n",
    "$$c_k = \\sum_{n = 0}^{N-1} x(n) e^{-i 2\\pi \\frac{kn}{N}} \\quad \\text{k'th fourier coefficient of a discrete signal}$$\n",
    "\n",
    "$$F_k = \\frac{k}{N}f_s \\quad \\text{Frequency corresponding the the k'th fourier coefficient} \\text{$k = 0 \\dots N$ if $N$ is even, $k = 0 \\dots N-1$ if $N$ is odd}$$\n",
    "\n",
    "$$A_k = \\frac{c_k}{N}\\cdot 2 \\quad \\text{Amplitude of the frequency corresponding to the k'th fourier coefficient}$$\n",
    "\n",
    "The rest is just a rehash of the first exercise from last time, if you feel somewhat comfortable calculating fourier coeffcients, you can skip this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1\n",
    "\n",
    "*You are given the following information about a sampled signal:\n",
    "\n",
    "- Sampling rate: $f_s = 4$\n",
    "- Duration: $1s$\n",
    "- Signal values $x(n) = [ 0,  1,  0, -1]$\n",
    "\n",
    "**1. Using the formula for fourier coefficients: $c_k = \\sum_{n = 0}^{N-1} x(n) e^{-i 2\\pi \\frac{kn}{N}}$, calculate the fourier coefficient for the signal $x(n)$ corresponding to $k = 1$**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**2. Calculate the frequency that the fourier coefficient for $k = 1$ corresponds to**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**3. Calculate the amplitude of the frequency that corresponds to the fourier coefficient for $k = 1$**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**4. Given the signal values for the above signal, what is the original analog signal?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**$\\star$ 5 Perform the same 4 exercises above but for $k = 3$ and for following values:**\n",
    "\n",
    "- Sampling rate: $f_s = 4$\n",
    "- Duration: $2s$\n",
    "- Signal values $x(n) = [ 0,     2.828, -4,     2.828,  0,    -2.828,  4,    -2.828]$\n",
    "\n",
    "\n",
    "$\\dots$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from scipy.io.wavfile import read\n",
    "from scipy.fft import fft, fftfreq, ifft # Technically used here is the fast fourier transform because it is... fast, don't convern yourself with this\n",
    "from scipy.signal import butter, filtfilt, convolve, stft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2\n",
    "\n",
    "*Far easier it is to create Python functions that calculate the fourier coeffcients for us*\n",
    "\n",
    "**1. The first of the below two functions generates a sine wave based on a series on input amplitudes, phases, frequencies, sample rates and a duration of the signal. The second should calculate the fourier coefficients of said sine wave. Complete the function to calculate the fourier coefficients.**\n",
    "\n",
    "**Test your imlpementation using the cell below, you shuold get back the amplitudes associated with each frequency**\n",
    "\n",
    "**2. Change the values of the sample rate, frequency, or duration to see if you can make a signal whose frequencies cannot be accurately represented by the fourier transform**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**3. What do you think happens with the fourier coefficients when the signal contains a frequency that does not correspond to any of the frequency bins?**\n",
    "\n",
    "$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sine_wave(amplitudes, frequencies, phases, sample_rate, duration):\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
    "    wave = sum([amplitudes[i] * np.sin(2 * np.pi * frequencies[i] * t + phases[i]) for i in range(len(frequencies))])\n",
    "    return wave\n",
    "\n",
    "def calculate_fourier_coeffcients(signal_values, sample_rate=1, v=True):\n",
    "    N = ...\n",
    "    coeffs = []\n",
    "\n",
    "    # Calculate fourier coefficient for each frequency bin\n",
    "    for k in range(N):\n",
    "        # Create values to sum in order to obtain fourier coefficients\n",
    "        prepared_to_sum = [... for n, x_n in enumerate(signal_values)]\n",
    "        coeffs.append(sum(prepared_to_sum))\n",
    "        \n",
    "        if v:\n",
    "            frequency = ...\n",
    "            absolute_coefficient = np.absolute(coeffs[k]) # Get absolute value to remove imaginary parts\n",
    "            print(f\"The fourier coeffcient associated with frequency {frequency}: {absolute_coefficient:.3f}, or an amplitude of {(2 * absolute_coefficient / N):.3f}\")\n",
    "            if k == N / 2:\n",
    "                print(\"############ Frequencies Loop ############\")\n",
    "\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = [0.5, 2] # Change these for 1.2.2\n",
    "amplitudes = [0.5, 1]\n",
    "phases = [0, 0, 0]\n",
    "\n",
    "sample_rate = 5 # Change this for 1.2.2\n",
    "duration = 2 # Change this for 1.2.2\n",
    "\n",
    "signal_values = generate_sine_wave(amplitudes, frequencies, phases, sample_rate, duration)\n",
    "coeffs = calculate_fourier_coeffcients(signal_values, sample_rate=sample_rate, v=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3\n",
    "\n",
    "*In practice, simply being above the nyquist rate isn't everything you need to get the lower frequencies. The amount of samples also has an effect*\n",
    "\n",
    "**1. Take a look at the below code, the fourier coefficient for the frequency 0.25 has not been found. Why is this?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**2. How can you change the values of sample_rate and duration to alleviate this problem?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**3. What would you say is a general rule of sampling when you need to recover both very high and very low frequencies?**\n",
    "\n",
    "$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = [0.25, 2]\n",
    "amplitudes = [0.5, 1]\n",
    "phases = [0, 0, 0]\n",
    "\n",
    "sample_rate = 5\n",
    "duration = 1\n",
    "\n",
    "signal_values = generate_sine_wave(amplitudes, frequencies, phases, sample_rate, duration)\n",
    "coeffs = calculate_fourier_coeffcients(signal_values, sample_rate=sample_rate, v=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Properties of the fourier transform\n",
    "\n",
    "*Two of the most touted properties of the fourier transform are arguably:*\n",
    "\n",
    "1. It is linear, meaning $F(aX + bY) =  a\\cdot F(X) + b \\cdot F(Y)$\n",
    "   1. This means, adding the scaled versions of signals in the time domain, equates to adding the scaled versions of their frequencies in the frequency domain\n",
    "2. Convolutions in the time domain are multiplications in the frequency domain and vice versa, often written as  $f(x) * h(k) = F(X) \\cdot H(X)$\n",
    "   1. You need not know what this means specifically, but we will use it more next week\n",
    "\n",
    "*We will just show the first in this exercise*\n",
    "\n",
    "**$\\star$ 1. Mathematically prove that the fourier transform (discrete case) is linear**\n",
    "\n",
    "*Hint: Look at two different functions x and y, not different values of k*\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**2. Show this condition of linearity by plotting what happens in the frequency domain when you add two scaled sine waves together. You can expand the cell below as a 'skeleton' for your code, or you can code it from scratch yourself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set duration of signal\n",
    "duraion = ...\n",
    "\n",
    "# Set sample rate\n",
    "sample_rate = ...\n",
    "\n",
    "# Create time values for signal\n",
    "t = ...\n",
    "\n",
    "\n",
    "# Define signals...\n",
    "frequency_1 = 1\n",
    "sine_wave_1 = ...\n",
    "\n",
    "frequency_2 = 2\n",
    "sine_wave_2 = ...\n",
    "\n",
    "# Create linear combination of signals\n",
    "a = 2\n",
    "b = 4\n",
    "signal_values = ...\n",
    "\n",
    "# Get coefficients using previous fourier coefficients function\n",
    "coeffs = ...\n",
    "\n",
    "\n",
    "# Plot signal in time and frequency domain\n",
    "plt.plot(t,signal_values)\n",
    "plt.show()\n",
    "\n",
    "plt.stem(coeffs[:10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Fourier transformations using packages\n",
    "\n",
    "*As ML enthusiasts, we obviously never implement ourselves what the plebs have already done for us. In this case, scipy already has a rather good FFT implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sk_fourier_transform(time_signal, duration, sample_rate):\n",
    "    \"\"\"\n",
    "    Use scipy to calculate the fft of a time signal\n",
    "    \"\"\"\n",
    "    \n",
    "    # Frequency domain (FFT)\n",
    "    N = ...\n",
    "    yf = ... # Fourier coefficients\n",
    "    xf = ... # Frequency values for the for the fourier coefficient bins\n",
    "    \n",
    "    # Get the timesteps that the signal exists over (just used for convenience, not needed for the FFT)\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
    "\n",
    "    return xf, yf, t\n",
    "\n",
    "\n",
    "def plot_audio_signal(t, signal_time, signal_freq, signal_freq_bins, duration=None):\n",
    "    \"\"\"\n",
    "    Plot a sine wave generated as as um of given frequencies, amplitudes and phases for a given duration with a givne sample rate\n",
    "\n",
    "    Args:\n",
    "        Same as play_sine_wave, lmao\n",
    "        If duration is none, will automatically figure out duration from max frequency so you can actually see the frequencies\n",
    "        This might lead to *some* aliasing in the plots themselves\n",
    "    \"\"\"\n",
    "    # Create duration of signal if not already there\n",
    "    if not duration:\n",
    "        duration = 100 / max(frequencies)\n",
    "\n",
    "    N = len(signal_time)\n",
    "    \n",
    "    # idx = np.arange(N // 2) # Complete to only take positive part of spectrum\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Time domain plot\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(t, signal_time)\n",
    "    plt.title(\"Audio signal in time domain\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot frequency domain\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.stem(signal_freq_bins, (1.0 / N * np.abs(signal_freq)))  # Normalized magnitude\n",
    "    plt.title(\"Audio signal in frequency domain\")\n",
    "    plt.xlabel(\"Frequency [Hz]\")\n",
    "    plt.ylabel(\"Magnitude\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1 \n",
    "\n",
    "*Using the FFT functions from scipy isn't actually **that** simple*\n",
    "\n",
    "**1. Complete the sk_fourier_transform function to get the fourier coefficients (yf) and the fourier frequency bins (xf) from a given time signal. If you're having trouble, be sure to look up documentation or examples online for this. Test your implementation using the cell below.**\n",
    "\n",
    "**$\\star$ 2. Change the plot_audio_signal function to only plot the positive frequencies, and get the wholly correct value of the amplitudes.**\n",
    "\n",
    "**3. Test the implementation in cases where there are frequencies that do not fit into frequency bins, and in cases were aliasing is present. How does the fourier spectrum look.**\n",
    "\n",
    "$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = [50, 100, 0.0005, 880, 7000]\n",
    "amplitudes = [0.5, 1, 10, 5, 8]\n",
    "phases = [0, 0, 0, 0, 0] \n",
    "\n",
    "sample_rate = 2500\n",
    "duration = 4\n",
    "\n",
    "time_signal = generate_sine_wave(amplitudes, frequencies, phases, sample_rate, duration)\n",
    "\n",
    "xf, yf, t = sk_fourier_transform(time_signal, duration, sample_rate)\n",
    "\n",
    "plot_audio_signal(t, time_signal, yf, xf, duration=duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2\n",
    "\n",
    "*In real life, we never have noise-free observations, so it is useful to see how noise affects our final signal as well as the fourier spectrum. The below code introduces normal distributed noise to a given signal with the following, common model:*\n",
    "\n",
    "$$y(n) = s_n + \\eta_n  \\text{ }|\\text{ }  \\eta_n \\sim \\mathcal{N}(0, \\sigma)$$\n",
    "\n",
    "*Where $s_n$ is our signal of interest, $\\eta_n$ is the system noise and $y(n)$ is our observed signal*\n",
    "\n",
    "**1. Complete the implementation to add noise to the observed time signal**\n",
    "\n",
    "**2. How does the fourier spectrum change when noise is introduced? How are the noise 'frequencies' expressed. Why do you think this is the case?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**3. Say you got an observed signal with noise as shown below, how could you approach removing the noise to only get the input frequencies out?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**3.1 Keeping in mind your idea for removing noise, how would increasing the variance of the noise impact this? Try increasing the variance of the noise and see what happens to the \"noise frequencies\" and the actual frequencies in the fourier spectrum**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**$\\star$ 3.2 The variance of the noise is often referred to as the \"power\" of the noise, why do you supose this is?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**$\\star$ 4. Try changing the mean value of the noise from 0 to add a so called \"DC component\". What do you think this represents? How is it reflected in the fourier spectrum?**\n",
    "\n",
    "$\\dots$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = [0.5, 2]\n",
    "amplitudes = [0.5, 2]\n",
    "phases = [0, 0] \n",
    "\n",
    "sample_rate = 50\n",
    "duration = 4\n",
    "\n",
    "time_signal = generate_sine_wave(amplitudes, frequencies, phases, sample_rate, duration)\n",
    "\n",
    "mean = 0 # Change this to introduce a 'dc component' to the noise\n",
    "variance = 1 # Change this to increase the prescence of the noise\n",
    "noise = ...       \n",
    "\n",
    "noised_signal = ...\n",
    "\n",
    "# Use preivously implemented fourier transform function to get the fourier coefficients\n",
    "xf, yf, t = ...\n",
    "\n",
    "plot_audio_signal(t, noised_signal, yf, xf, duration=duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3\n",
    "\n",
    "*Another really useful property of the fourier transform, is that we as humans just cannot get much information from the time spectrum in general. Below is code to plot two different noised signals in the time and frequency domain. T*\n",
    "\n",
    "**1. Consider the two noised signals below. Here the exercise is mostly to realize the importance of the frequency domain, especially in tasks that require pinpointing specific frequencies in signals. In the time domain, the signals look almost identical, in the frequency domain, there is a huge and obvious difference.**\n",
    "\n",
    "**You will see this be useful again next week during assignment 2 when you need to classify brain waves based on their frequency content.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_signal_1 = [0.5, 2, 5]\n",
    "amplitudes_signal_1 = [0.5, 1, 2]\n",
    "\n",
    "frequencies_signal_2 = [20]\n",
    "amplitudes_signal_2 = [5]\n",
    "\n",
    "phases = [0, 0, 0] \n",
    "\n",
    "sample_rate = 50\n",
    "duration = 4\n",
    "\n",
    "time_signal_1 = generate_sine_wave(amplitudes_signal_1, frequencies_signal_1, phases, sample_rate, duration)\n",
    "time_signal_2 = generate_sine_wave(amplitudes_signal_2, frequencies_signal_2, phases, sample_rate, duration)\n",
    "\n",
    "noise = np.random.normal(loc=0, scale=4, size=len(time_signal_1))\n",
    "\n",
    "noised_signal_1 = time_signal_1 + noise\n",
    "noised_signal_2 = time_signal_2 + noise\n",
    "\n",
    "xf_1, yf_1, t = sk_fourier_transform(noised_signal_1, duration, sample_rate)\n",
    "plot_audio_signal(t, noised_signal_1, yf_1, xf_1, duration=duration)\n",
    "\n",
    "xf_2, yf_2, t = sk_fourier_transform(noised_signal_2, duration, sample_rate)\n",
    "plot_audio_signal(t, noised_signal_2, yf_2, xf_2, duration=duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.4\n",
    "\n",
    "*As previously mentioned, most of human speech is typically around the 90 - 3500 Hz range. It can be interesting to look at actual voice signals to see how they behave. The cell below loads one of four voice signals spelling out \"S O F A\"*\n",
    "\n",
    "*We redefine fourier transform and plotting functions to work with loaded data*\n",
    "\n",
    "1. *A clean signal where only the speech is present*\n",
    "2. *A signal where white noise has been added in the background*\n",
    "3. *A signal where non-white noise in the form of a fan has been added*\n",
    "4. *A signal where non-white noise in the form of human speech has been added*\n",
    "\n",
    "**1. Load the clean signal and see if you can recognize the difference between consonants and vowels in the time domain, what about the frequency domain?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**2. Load the two different noised signals. How do the different types of noise stand out from one another?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**3. Play with the function mix_noise to mix different types of noise with the clean signal. What combinations of noise make the clean signal the most unintelligeble from an audio standpoint?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**3.1 What combinations of noise make the clean signal the most unintelligeble when looking at just the plot of the time and frequency domain**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**4. In general, what types of the presented noise do you think are the most difficult to remove out when the clean signal is human speech?**\n",
    "\n",
    "$\\dots$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine fourier transform and plot functions because they don't really work when we have signals with set durations\n",
    "def sk_fourier_transform(time_signal, t, sample_rate):\n",
    "    \"\"\"\n",
    "    Use scipy to calculate the fft of a time signal\n",
    "    \"\"\"\n",
    "    # Get the timesteps that the signal exists over\n",
    "    t = np.linspace(0, time_signal.size / sample_rate, time_signal.size, endpoint=False)\n",
    "    \n",
    "    # Frequency domain (FFT)\n",
    "    N = len(time_signal)\n",
    "    yf = fft(time_signal) # Fourier coefficients\n",
    "    xf = fftfreq(N, 1 / sample_rate) # Frequency values for the for the fourier coefficient bins\n",
    "    \n",
    "    return xf, yf, t\n",
    "\n",
    "\n",
    "def plot_audio_signal(t, signal_time, signal_freq, signal_freq_bins, duration=None, max_freq=5000):\n",
    "    \"\"\"\n",
    "    Plot a sine wave generated as as um of given frequencies, amplitudes and phases for a given duration with a givne sample rate\n",
    "\n",
    "    Args:\n",
    "        Same as play_sine_wave, lmao\n",
    "        If duration is none, will automatically figure out duration from max frequency so you can actually see the frequencies\n",
    "        This might lead to *some* aliasing in the plots themselves\n",
    "    \"\"\"\n",
    "    # Create duration of signal if not already there\n",
    "    if not duration:\n",
    "        duration = 100 / max(frequencies)\n",
    "\n",
    "    N = len(signal_time)\n",
    "    \n",
    "    idx = np.arange(N // 2) # Complete to only take positive part of spectrum\n",
    "\n",
    "    if max_freq is not None and max_freq > 0:\n",
    "        idx = idx[:max_freq]\n",
    "\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Time domain plot\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(t, signal_time)\n",
    "    plt.title(\"Audio signal in time domain\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot frequency domain\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(signal_freq_bins[idx], (2.0 / N * np.abs(signal_freq[idx])))  # Normalized magnitude\n",
    "    plt.title(\"Audio signal in frequency domain\")\n",
    "    plt.xlabel(\"Frequency [Hz]\")\n",
    "    plt.ylabel(\"Magnitude\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sofa_path = \"audio/sofa.wav\"\n",
    "fan_noise_path = \"noise_examples/fan_noise.wav\"\n",
    "talking_path = \"noise_examples/talking.wav\"\n",
    "\n",
    "sample_rate, time_signal = read(sofa_path)\n",
    "time_signal = 5 * np.array(time_signal[1:, 0],dtype=float)   # Indexed to make N odd\n",
    "\n",
    "\n",
    "def mix_noise(observed_signal, noise_paths, noise_amplitudes, white_noise_variance=10, whtie_noise_mean=0, white_noise_amplitude=10):\n",
    "    \"\"\"\n",
    "    Load and mix different white noise sources\n",
    "    \"\"\"\n",
    "    # Work with a copy of the observed signal so we don't corrupt the original input signal\n",
    "    observed_signal_copy = np.copy(observed_signal)\n",
    "\n",
    "    for noise_path, noise_amplitude in zip(noise_paths, noise_amplitudes):\n",
    "        # Load in noised signal\n",
    "        _, noise_signal = read(noise_path)\n",
    "        # Convert to np array (as above) and index to make sure it is as long as the observed signal\n",
    "        noise_signal = ...\n",
    "        # Mix with observed signal by adding as a weighted sum\n",
    "        observed_signal_copy += ...\n",
    "\n",
    "    # Create and add white noise - Remember to have as many white noise samples as the length of the signal\n",
    "    white_noise = ...\n",
    "    # Mix with observed signal, same as above\n",
    "    observed_signal += ...\n",
    "\n",
    "    return observed_signal_copy\n",
    "\n",
    "\n",
    "# Use function just defined above\n",
    "time_signal = mix_noise(...)\n",
    "\n",
    "# Create fourier transform, plot signal\n",
    "xf, yf, t = sk_fourier_transform(time_signal, duration, sample_rate)\n",
    "plot_audio_signal(t, time_signal, yf, xf, duration=duration, max_freq=5000)\n",
    "\n",
    "# Play audio as a widget - Way better than using sounddevice\n",
    "Audio(time_signal,rate = sample_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Reflections on noise\n",
    "\n",
    "### Exercise 4.1\n",
    "\n",
    "*Noise is present everywhere, but can be circumvented in quite a few cases. The following questions are mostly discussion and reflection questions, there may not be a 'true answer'*\n",
    "\n",
    "**1. Alice uses her phone to call Bob. Alice's phone signal occupies the frequency range 600MHz to 1GHz (somewhat normal for phones). Charlie is right next to Alice during her call, and is watching a Joe Rogan podcast using Wifi, which he recieves on the frequency band 2.4GHz to 5GHz.**\n",
    "\n",
    "**1.1 Is the call between Alice and Bob in danger of being cut off? Why/Why not?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**1.2 Say Charlie *wants* to mess with Alice and Bob by interrupting their call. How could he go about this?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**2. Reflect on what can cause noise in the following scenarios:**\n",
    "\n",
    "1. **Talking in a crowded room**\n",
    "2. **A phone getting wifi signal in a crowded mall**\n",
    "3. **An alien race sending a signal to earth so NASA can hear it.**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**3. You are an engineer working for the well-known and respected military contractor, Suckheed Fartin (Skibidi Gyattin). Recently, the military has been having issues where nasty people have used radios to send mean messages to the pilots of fighter jets flying missions, this of course makes the pilots very sad, and the military wants a solution.**\n",
    "\n",
    "**How would you, armed with your newfound knowledge of signal processing, go about solving the issue of these mean messages. For practical purposes, the pilots cannot turn off their radios or change the reciever frequencies on their radios**\n",
    "\n",
    "$\\dots$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Filtering\n",
    "\n",
    "As mentioned, filtering is rather easy enough, we are going to focus on just convolution, plotting filters and using filters in time and frequency domain. As a reminder, the formula for signal convolution is\n",
    "\n",
    "$$y(k) = x(n) * h(n) = \\sum^{\\infty}_{n=-\\infty} x(n) h(k - n)$$\n",
    "\n",
    "## High-, low, and band-pass filtering\n",
    "\n",
    "The most commonly used filters, are usually some variant of high-pass filters, low-pass filters and band-pass filters. They work in the following ways:\n",
    "\n",
    "- **High-pass**: Let the high frequencies pass, meaning the result is a signal with only high frequencies\n",
    "- **Low-pass**: Let the low frequencies pass, meaning the signal will only have low frequencies\n",
    "- **Band-pass**: Let frequencies in a specific band (for example 400 to 800 Hz) pass, meaning the signal will only have those frequencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1\n",
    "\n",
    "*It is good thing to try at least one manual calculation of convolution with a filter, as terrible as it may sound...*\n",
    "\n",
    "**1. Given the below values:**\n",
    "\n",
    "$$x_n = \\begin{cases} \n",
    "        \\frac{1}{2} n  & \\text{for} 0 \\leq n \\leq 6 \\\\\n",
    "        0 & \\text{elsewhere}\n",
    "        \\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "$$h_n = \\begin{cases} \n",
    "        1  & \\text{for} -2 \\leq n \\leq 2 \\\\\n",
    "        0 & \\text{elsewhere}\n",
    "        \\end{cases}\n",
    "$$\n",
    "\n",
    "**Calculate $y(k)$ as a of the convolution $x(k) * h(k)$ for $k = -1$, $k = 4$ and $k = 7$**\n",
    "\n",
    "$\\dots$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.2\n",
    "\n",
    "*I meant to have an exercise centered around implementing your own convolution function to use a pre-made filter to do low-pass filtering... However that was prohibitively overcomplicated. Take that as a lesson, that if someone else has done it, it is probably better than what you can make yourself*\n",
    "\n",
    "*That said, we still wanna 'get' filtering. Both manually and using packages. Below the functions butter_lowpass and butter_lospass_filter create a so-called [butterworth](https://en.wikipedia.org/wiki/Butterworth_filter) filter and apply it to a signal respectively.*\n",
    "\n",
    "**1. Inspect the plots created by running the code two cells below. What are the visibile effects on time and frequency domain?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**2. Change the value of the frequency_cutoff, how does this change the plots and the resulting audio?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**$\\star$ 3. The Butterworth filter is described as a 'maximally flat magnitude filter' what do you think this refers to. Why can we in actuality not just construct a completely flat filter?**\n",
    "\n",
    "$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    \"\"\"\n",
    "    Create a butterworth lowpass filter, given a cutoff frequency and sampling rate\n",
    "    \"\"\"\n",
    "    # Nyquist rate\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    \n",
    "    # Use scipy to get butter filter\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    \"\"\"\n",
    "    Create and apply a butterworth lowpass filter to a signal\n",
    "    \"\"\"\n",
    "    # Create lowpass filter using afforementioned function\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    # Apply filter using filtfilt function\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sofa example, same as before\n",
    "sofa_path = \"audio/sofa.wav\"\n",
    "sample_rate, time_signal = read(sofa_path)\n",
    "time_signal = np.array(time_signal[1:, 0],dtype=float)\n",
    "\n",
    "# Filter time signal using butter lowpass filter, only let frequencies of frequency_cutoff pass\n",
    "frequency_cutoff = 1000\n",
    "filtered_signal = butter_lowpass_filter(time_signal, 1000, fs=sample_rate, order= 5)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(8, 12))\n",
    "\n",
    "# Plot the original signal in the time domain\n",
    "axs[0, 0].plot(np.arange(len(time_signal)), time_signal)\n",
    "axs[0, 0].set_title('Original Signal, time domain')\n",
    "axs[0, 0].set_xlabel('Time')\n",
    "axs[0, 0].set_ylabel('Magnitude')\n",
    "\n",
    "# Plot the filtered signal in the time domain\n",
    "axs[0, 1].plot(np.arange(len(filtered_signal)), filtered_signal)\n",
    "axs[0, 1].set_title('Filtered Signal, time domain')\n",
    "axs[0, 1].set_xlabel('Time')\n",
    "axs[0, 1].set_ylabel('Magnitude')\n",
    "\n",
    "# Obtain freqeuncy domain\n",
    "xf = fftfreq(len(time_signal), 1 / sample_rate)\n",
    "yf_original = np.abs(fft(time_signal))\n",
    "yf_filtered = np.abs(fft(filtered_signal))\n",
    "\n",
    "# Plot the original signal in the frequency domain\n",
    "axs[1, 0].plot(xf, yf_original)\n",
    "axs[1, 0].set_title('Original signal, frequency domain')\n",
    "axs[1, 0].set_xlabel('Frequency')\n",
    "axs[1, 0].set_ylabel('Magnitude')\n",
    "\n",
    "# Plot the filtered signal in the frequency domain\n",
    "axs[1, 1].plot(xf, yf_filtered)\n",
    "axs[1, 1].set_title('Filtered signal, frequency domain')\n",
    "axs[1, 1].set_xlabel('Frequency')\n",
    "axs[1, 1].set_ylabel('Magnitude')\n",
    "\n",
    "\n",
    "Audio(filtered_signal, rate = sample_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\star$ Exercise 5.3\n",
    "\n",
    "*Below we implement filtering manually, which can be scary. We do this in two ways: One is simply multiplying the values in the frequency spectrum. The other is using the filter from the aforementioned method to convolve the signal in time domain. This avoids the somewhat more stringent math of creating filters in the time domain.*\n",
    "\n",
    "**1. Complete the code to perform filtering in the frequency domain** \n",
    "\n",
    "**2. Inspect the plots of the filtering code. Determine what kind of filter it is by looking at its impulse response, as well as the fourier spectrum of the filtered signal**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**3. Change the type of the filter by changing the cutoff_freq parameter. Try to make a high-pass filter and a band-pass filter. Listen to the resulting audio from both these**\n",
    "\n",
    "**$\\star \\star$ 4. As mentioned, we can also filter in the time domain. Do so using the apply_convolution function and answer the following questions:**\n",
    "\n",
    "1. What do we use the IFFT for?\n",
    "2. Why do we use np.roll?\n",
    "3. What is the result of the convolution compared to frequency domain filtering?\n",
    "\n",
    "$\\dots$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_domain_filtering(time_signal : np.ndarray, sample_rate : int, cutoff_freq : list):\n",
    "    \"\"\"\n",
    "    Filter a signal by multiplying its fourier transform with specific values\n",
    "    Args:\n",
    "        time_signal (np.ndarray): input time-domain signal\n",
    "        sample_rate (int): sampling rate of the signal\n",
    "        cutoff_freq (list): list of [low_cutoff, high_cutoff] frequencies\n",
    "    \"\"\"\n",
    "\n",
    "    # Get fourier transform and fourier bins\n",
    "    yf = fft(time_signal)\n",
    "    xf = fftfreq(len(time_signal), 1 / sample_rate)\n",
    "\n",
    "    # Find the index in the yf array corresponding to the cutoff frequencies\n",
    "    idx_lowpass = ...\n",
    "    idx_highpass = ...\n",
    "\n",
    "    # Create a frequency mask (both positive and negative frequencies are included)\n",
    "    frequency_mask = np.zeros(len(xf))\n",
    "    # Set all values in the frequency mask to pass through the filter\n",
    "    frequency_mask[idx_lowpass:idx_highpass] = 1\n",
    "    frequency_mask[-idx_highpass:-idx_lowpass if cutoff_freq[0] > 0 else len(xf)] = 1  # Handle negative frequencies as well\n",
    "    \n",
    "    # Apply the frequency mask to the Fourier transformed values\n",
    "    yf_filtered = ...\n",
    "    \n",
    "    # Perform inverse Fourier transform to get filtered time-domain signal\n",
    "    filtered_signal = ...\n",
    "\n",
    "    return filtered_signal, frequency_mask\n",
    "\n",
    "def apply_convolution(time_signal: np.ndarray, frequency_mask: np.ndarray):\n",
    "    \"\"\"\n",
    "    Apply convolution using a filter kernel obtained from inverse FFT of the frequency mask.\n",
    "    Args:\n",
    "        time_signal (np.ndarray): Original time-domain signal.\n",
    "        frequency_mask (np.ndarray): Frequency mask used in the filtering process.\n",
    "    Returns:\n",
    "        convolved_signal (np.ndarray): Signal after applying convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtain the filter kernel by inverse Fourier transform of the frequency mask\n",
    "    filter_kernel = np.real(ifft(frequency_mask))\n",
    "    \n",
    "    # Shift kernel to be centered (necessary since the kernel is symmetric)\n",
    "    filter_kernel = np.roll(filter_kernel, len(filter_kernel) // 2)\n",
    "\n",
    "    # Perform convolution with the time signal (if using convolution methods, don't use your own, use scipy's (it's faster))\n",
    "    convolved_signal = convolve(time_signal, filter_kernel, mode='same')\n",
    "\n",
    "    return convolved_signal, filter_kernel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio same as before...\n",
    "sofa_path = \"audio/sofa.wav\"\n",
    "sample_rate, time_signal = read(sofa_path)\n",
    "time_signal = np.array(time_signal[1:, 0],dtype=float)\n",
    "\n",
    "# Filter the signal in frequency domain\n",
    "filtered_signal, frequency_mask = frequency_domain_filtering(time_signal, sample_rate, cutoff_freq=[0, 380])\n",
    "\n",
    "# Filter signal in time domain\n",
    "convolved_signal, time_filter = apply_convolution(time_signal, frequency_mask)\n",
    "\n",
    "# Obtain the FFT of the original and filtered signals respectively\n",
    "original_freq_domain = np.abs(fft(time_signal))\n",
    "filtered_freq_domain = np.abs(fft(filtered_signal))\n",
    "\n",
    "\n",
    "############## PLOTTING ##############\n",
    "\n",
    "# Create a 3x2 subplot layout\n",
    "fig, axs = plt.subplots(2, 3, figsize=(20, 15))\n",
    "\n",
    "# Plot the filter kernel in frequency domain\n",
    "axs[0, 0].plot(np.arange(len(frequency_mask[:len(frequency_mask) // 2])), frequency_mask[:len(frequency_mask) // 2])\n",
    "axs[0, 0].plot(frequency_mask)\n",
    "axs[0, 0].set_title('Created (bandpass) filter in Fourier spectrum')\n",
    "axs[0, 0].set_xlabel('Frequency bins')\n",
    "axs[0, 0].set_ylabel('Magnitude')\n",
    "\n",
    "# Plot filter in time domain\n",
    "# time_filter_limited = time_filter[len(time_filter) // 2 - 250: len(time_filter) // 2 + 250] # If you want to see the middle of the filter\n",
    "# Get the first 300 and last 300 indices of the time filter\n",
    "first = time_filter[1:300]\n",
    "last = time_filter[-300:-1]\n",
    "time_filter_limited = np.concatenate((first, last))\n",
    "axs[1, 0].plot(np.arange(len(time_filter_limited)), time_filter_limited)\n",
    "axs[1, 0].set_title('Created (bandpass) filter in time domain')\n",
    "axs[1, 0].set_xlabel('k')\n",
    "axs[1, 0].set_ylabel('h(k)')\n",
    "\n",
    "# Plot the original time signal\n",
    "axs[0, 1].plot(np.arange(len(time_signal)), time_signal)\n",
    "axs[0, 1].set_title('Original Time Signal')\n",
    "axs[0, 1].set_xlabel('Sample index')\n",
    "axs[0, 1].set_ylabel('Amplitude')\n",
    "\n",
    "# Plot the convolved signal\n",
    "axs[1, 1].plot(np.arange(len(filtered_signal)), filtered_signal)\n",
    "axs[1, 1].set_title('Filtered Signal')\n",
    "axs[1, 1].set_xlabel('Sample index')\n",
    "axs[1, 1].set_ylabel('Amplitude')\n",
    "\n",
    "# Plot the Fourier domain of the original signal\n",
    "axs[0, 2].plot(np.arange(len(original_freq_domain)), original_freq_domain)\n",
    "axs[0, 2].set_title('Fourier spectrum of Original Signal')\n",
    "axs[0, 2].set_xlabel('Frequency bins')\n",
    "axs[0, 2].set_ylabel('Magnitude')\n",
    "\n",
    "# Plot the Fourier domain of the filtered signal\n",
    "axs[1, 2].plot(np.arange(len(filtered_freq_domain)), filtered_freq_domain)\n",
    "axs[1, 2].set_title('Fourier spectrum of Filtered Signal')\n",
    "axs[1, 2].set_xlabel('Frequency bins')\n",
    "axs[1, 2].set_ylabel('Magnitude')\n",
    "\n",
    "# Display the audio created\n",
    "Audio(filtered_signal, rate = sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6 - The Short-Time Fourier transform\n",
    "\n",
    "\n",
    "\n",
    "*There is something called the short time fourier transform (STFT). What this does is split a time signal into a bunch of smaller time intervals, and computes the fourier transform for each smaller interval. Laying all of these FT's in series produces what is known as a spectogram, which you may have already know from Intro to Intelligent systems*\n",
    "\n",
    "**1. Why would you do this?**\n",
    "\n",
    "The answer can vary, but the main reason is in use for signals where the frequency content can change quickly. Take for example human speech where the frequency content can change widely depending on what is being said.\n",
    "\n",
    "Another example (that I am currently working on), is when you have a signal that has been filtered with an unknown signal and need to unfilter it. The STFT lets you amplify or attentuate frequencies on specific timesteps, rather than frequencies over the entire time domain. This lets you have much greater dergree of granularity when doing inverse problems such as that.\n",
    "\n",
    "\n",
    "**2. How do you implement this?**\n",
    "\n",
    "Shown below. You need a few more parameters that the regular FT, most of which determine how the different time segments overlap. The 'window' parameter is a kind of filter that determines how one or more time segments overlap, while the nperseg is how many time units is used for each segment. A larger number creates a more 'mean value' for each segment and has smoother transitions, as well as being faster, while a smaller value gives greater granularity in what the frequency content is at a specific timestep, but can vary more and is slower.\n",
    "\n",
    "\n",
    "**3. What extra things do you do to make the spectogram look nice?**\n",
    "\n",
    "A bunch. I'm not an audio engineer or anything like that, but it includes these changes to make the spectogram more \"visually appealing\", including:\n",
    "\n",
    "- Thresholding the frequency magnitudes by the n'th percentile to remove unecessary frequencies which could otherwise \"pollute\" the plots\n",
    "- Converting the magnitude of the FFT to dB (by multiplying by 20 and taking log10)\n",
    "- Smoothing the dB values using a gaussian filter to just make them less \"janky\"\n",
    "\n",
    "\n",
    "**Just to reiterate: YOU DO NOT NEED TO UNDERSTAND BELOW CODE!!! It's mostly (boring) plotting stuff, some of it made by chatgpt and such**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## MATPLOTLIB AND NUMPY IMPLEMENTATION - LESS 'BLACK BOXY' ###########\n",
    "# def plot_stft(time_signal, sample_rate, max_freq=10000,\n",
    "#                 smooth=True, convert_to_db=True, \n",
    "#                 threshold=75, title=None):\n",
    "    \n",
    "#     # Perform STFT\n",
    "#     f, t, Zxx = stft(time_signal, fs=sample_rate, nperseg=1024,  window='hamming')\n",
    "\n",
    "#     # Filter out the frequencies above the desired range\n",
    "#     freq_mask = f <= max_freq\n",
    "#     f_filtered = f[freq_mask]\n",
    "#     Zxx_filtered = Zxx[freq_mask, :]\n",
    "\n",
    "#     Zxx_magnitude = np.abs(Zxx_filtered)\n",
    "    \n",
    "#     if threshold: # If trehsold is set, remove all values below the (to reinforce the most important parts of the signal)\n",
    "#         threshold = np.percentile(Zxx_magnitude, 75)\n",
    "#         Zxx_magnitude[Zxx_magnitude < threshold] = 0\n",
    "    \n",
    "#     if convert_to_db:\n",
    "#         Zxx_magnitude_db = 20 * np.log10(Zxx_magnitude + 1e-10)  # Add a small epsilon to avoid log(0)\n",
    "        \n",
    "#     else:\n",
    "#         Zxx_magnitude_db = Zxx_magnitude\n",
    "\n",
    "#     if smooth: # Smoothing to make the plot more visually appealing\n",
    "#         from scipy.ndimage import gaussian_filter\n",
    "#         Zxx_magnitude_db = gaussian_filter(Zxx_magnitude_db, sigma=0.5)\n",
    "\n",
    "#     # Plot the spectrogram, here we use pcolormesh, since there is tehnically like three axes\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.pcolormesh(t, f_filtered, Zxx_magnitude_db, shading='gouraud')\n",
    "#     if not title:\n",
    "#         plt.title('Spectrogram of the Audio Signal')\n",
    "#     else:\n",
    "#         plt.title(title)\n",
    "#     plt.ylabel('Frequency [Hz]')\n",
    "#     plt.xlabel('Time [sec]')\n",
    "#     plt.colorbar(label='Magnitude (dB)')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "    # return time_signal, sample_rate\n",
    "\n",
    "\n",
    "# def load_file_and_plot_stft(file_path, start_duration=None, **kwargs):  \n",
    "#     \"\"\"\n",
    "#     Just a convenience function to load a file *and* plot the stft of it\n",
    "#     \"\"\"\n",
    "#     sample_rate, time_signal = read(file_path)\n",
    "\n",
    "#     if start_duration:\n",
    "#         time_signal = time_signal[start_duration[0]*sample_rate: start_duration[0]*sample_rate +  start_duration[1]*sample_rate]\n",
    "\n",
    "#     # Pre-process time signal\n",
    "#     time_signal = np.array(time_signal[1:, 0], dtype=float)  # Indexed to make N odd\n",
    "\n",
    "\n",
    "#     time_signal, sample_rate = plot_stft(time_signal, sample_rate, **kwargs)\n",
    "#     return time_signal, sample_rate\n",
    "\n",
    "# _ = load_file_and_plot_stft('audio/sofa.wav', title='Spectogram S O F A example')\n",
    "\n",
    "# sample_rate, time_signal = read('R060_004.wav')\n",
    "# time_signal = np.array(time_signal[1:, 0], dtype=float)  # Indexed to make N odd\n",
    "\n",
    "\n",
    "######### LIBROSA IMPLEMENTATION - MIGHT BE BETTER #########\n",
    "import librosa\n",
    "import librosa.display\n",
    "def plot_stft(time_signal, sample_rate, max_freq=10000,\n",
    "                mel=True, title=None, **kwargs):\n",
    "\n",
    "    # Compute spectrogram - Use mel spectogram to better capture frequencies of note\n",
    "    if mel:\n",
    "        spec = librosa.feature.melspectrogram(y=time_signal, sr=sample_rate)\n",
    "    else:\n",
    "        spec = np.abs(librosa.stft(y=time_signal)) ** 2\n",
    "    # Convert power to decibels\n",
    "    spec_db = librosa.power_to_db(spec, ref=np.max)\n",
    "\n",
    "    # Plot spectrogram\n",
    "    # fig, ax = plt.subplots(nrows = 1, ncols = 1)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    img = librosa.display.specshow(spec_db, x_axis='time', y_axis='mel')\n",
    "    # plt.colorbar(img, ax = ax, format='%+2.0f dB')\n",
    "    plt.colorbar(img, format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    return time_signal, sample_rate\n",
    "\n",
    "def load_file_and_plot_stft(file_path, start_duration=[0, None], **kwargs):\n",
    "    # Load audio file\n",
    "    time_signal, sample_rate = librosa.load(file_path, offset=start_duration[0], duration=start_duration[1], mono=True)\n",
    "    plot_stft(time_signal, sample_rate, **kwargs)\n",
    "    return time_signal, sample_rate\n",
    "\n",
    "_, _ = load_file_and_plot_stft('audio/sofa.wav')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.1 \n",
    "\n",
    "*STFT and filtering is often used together. Here we play around with different types of filtering*\n",
    "\n",
    "**1. Use both low-pass and high-pass on the sofa example before and plot the STFT**\n",
    "\n",
    "**$\\star$ 2. Plot the STFT for one the noised sofa examples and see if you can clean the STFT somewhat using filtering, or by changing the settings of the STFT plot (such as threshold). Specifically see if you can solve the following problems:**\n",
    "\n",
    "1. Remove (most) of the fan noise using a high-pass filter\n",
    "2. Remove (most) of the white noise using low-pass filter\n",
    "3. Try (and no doubt fail) to remove some of the talking noise using whatever filter you feel would be appropriate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio same as before...\n",
    "sofa_path = \"audio/sofa.wav\"\n",
    "sample_rate, time_signal = read(sofa_path)\n",
    "time_signal = np.array(time_signal[1:, 0],dtype=float)\n",
    "\n",
    "# Create signal noised by the fan\n",
    "fan_noised_signal = mix_noise(observed_signal=time_signal, noise_paths=[fan_noise_path, talking_path], noise_amplitudes=[0.5, 0], white_noise_amplitude=0)\n",
    "# Filter out fan noise...\n",
    "fan_filtered_noised_signal, _ = ...\n",
    "\n",
    "# Create signal with white noise\n",
    "white_noised_signal = mix_noise(observed_signal=time_signal, noise_paths=[fan_noise_path, talking_path], noise_amplitudes=[0, 0], white_noise_amplitude=50)\n",
    "# Filter out white noise...\n",
    "white_filtered_noised_signal, _ = ...\n",
    "\n",
    "# Create signal noised by speech\n",
    "speech_noised_signal = mix_noise(observed_signal=time_signal, noise_paths=[fan_noise_path, talking_path], noise_amplitudes=[0, 1], white_noise_amplitude=0)\n",
    "# Filter out speech noise\n",
    "speech_filtered_noised_signal, _ = ...\n",
    "\n",
    "# Plot and play resulting audio\n",
    "plot_stft(speech_noised_signal, sample_rate, max_freq=5000, smooth=True, convert_to_db=True, threshold=75, title=\"Spectogram of noised data\")\n",
    "Audio(speech_filtered_noised_signal, rate = sample_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.2 (Easy)\n",
    "\n",
    "**Having such a \"clean\" audio where there is almost no sound in many places is a big boring to look at, having for example a music clip might be more interesting...**\n",
    "\n",
    "**Here is where the exercises end. If you want, I've collected a bunch of different examples of sound in the extra_spectograms folder that I think would be interesting to see both the spectogram of, if not also the fourier transform and the time domain signal. You can plot them using the below code if you want**\n",
    "\n",
    "**Note, you can change the 'max_freq' if you want to see higher frequencies or want greater resolution on the lower frequencies.**\n",
    "\n",
    "**If you want, you can also play around with the filters from before to see if you can get truly cursed stft's or audio...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import titles\n",
    "\n",
    "# Three typical examples of young-people music\n",
    "time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/good_music.wav\", max_freq=5000, start_duration=[30, 15], title=titles.all_titles[0])\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/hutcher.wav\", max_freq=5000, title=titles.all_titles[1])\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/broken.wav\", max_freq=5000, title=titles.all_titles[2])\n",
    "\n",
    "# A bass singer (low pitch)\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/bass_singer.wav\", max_freq=5000, title=titles.all_titles[3])\n",
    "\n",
    "# A tenor singer (high pitch)\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/tenor_singer.wav\", max_freq=5000, title=titles.all_titles[4])\n",
    "\n",
    "# A guitar solo (medium pitch)\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/guitar_solo.wav\", max_freq=10000, title=titles.all_titles[5])\n",
    "\n",
    "# A bass solo (low pitch)\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/bass_solo.wav\", max_freq=5000, title=titles.all_titles[6])\n",
    "# A songbird (perhaps distortion)\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/songbird.wav\", max_freq=5000, title=titles.all_titles[7])\n",
    "\n",
    "# A human songbird (????)\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/human_songbird.wav\", max_freq=5000, title=titles.all_titles[8])\n",
    "\n",
    "# A bunch of people talking at the same time\n",
    "# time_signal, sample_rate = load_file_and_plot_stft(\"extra_spectograms/people_talking.wav\", max_freq=5000, title=titles.all_titles[9])\n",
    "\n",
    "\n",
    "# TODO: Optionally apply some filtering here\n",
    "# time_signal, frequency_mask = frequency_domain_filtering(time_signal, sample_rate, cutoff_freq=[2000, 4000])\n",
    "\n",
    "# If you want to play the audio\n",
    "Audio(time_signal,rate = sample_rate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sign-dat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
